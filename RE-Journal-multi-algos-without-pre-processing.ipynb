{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "#import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim      2076\n",
      "feature     667\n",
      "issue       308\n",
      "Name: Rationale_Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('google-maps-single-dataset-for-conference.csv',encoding='ISO-8859-1')\n",
    "df = df[pd.notnull(df['Rationale_Type'])]\n",
    "df = df.replace(\"issue \", \"issue\")\n",
    "print(df.Rationale_Type.value_counts())\n",
    "#print(df.head(10))\n",
    "#print(df['comment_Text'].apply(lambda x: len(x.split(' '))).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_tags = ['new feature','claim','issue']\n",
    "plt.figure(figsize=(10,4))\n",
    "df.Rationale_Type.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_Text'].values.astype('U')\n",
    "y = df['Rationale_Type'].values.astype('U')\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "#print(len(X_train))\n",
    "#print(len(X_test))\n",
    "#x = v.fit_transform(df['Review'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added extra\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    #fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    #predictions the labels on validation dataset\n",
    "    predictions= classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions= predictions.argmax(axis= -1)\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average accuracy of NBM is 0.6090024643737277\n",
      "the average accuracy of SVM is 0.44544090860387875\n",
      "the average accuracy of LR is 0.5798242794385514\n",
      "the average accuracy of RF is 0.5863720132861887\n",
      "[[  0.7898459    0.41812119   0.25866288]\n",
      " [  0.65409143   0.54501044   0.40298191]\n",
      " [  0.71392954   0.46729119   0.31107285]\n",
      " [207.6         66.7         30.8       ]]\n",
      "[[6.93016003e-01 3.65093307e-01 1.29328672e-01]\n",
      " [5.28683288e-01 1.56175154e-01 5.05222330e-01]\n",
      " [5.95645480e-01 2.16665684e-01 2.03542110e-01]\n",
      " [2.07600000e+02 6.67000000e+01 3.08000000e+01]]\n",
      "[[7.68133521e-01 4.14849418e-01 2.06604863e-01]\n",
      " [6.24274075e-01 5.12156463e-01 3.66367328e-01]\n",
      " [6.87771431e-01 4.54597861e-01 2.58425728e-01]\n",
      " [2.07600000e+02 6.67000000e+01 3.08000000e+01]]\n",
      "[[7.05096293e-01 3.43082561e-01 1.55023130e-01]\n",
      " [7.52079864e-01 2.49421416e-01 1.79850193e-01]\n",
      " [7.26535383e-01 2.86199477e-01 1.63181490e-01]\n",
      " [2.07600000e+02 6.67000000e+01 3.08000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "#Kfold classification for NBM, SVM, LR and RF using countvectorizor\n",
    "\n",
    "kf= KFold(n_splits=10)\n",
    "#curr_fold= 0\n",
    "alg_accurcy_NBM =[]\n",
    "alg_accurcy_SVM =[]\n",
    "alg_accurcy_LR =[]\n",
    "alg_accurcy_RF =[]\n",
    "\n",
    "score_array_NBM= []\n",
    "score_array_SVM= []\n",
    "score_array_LR= []\n",
    "score_array_RF= []\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test= X[train_idx], X[test_idx]\n",
    "    y_train, y_test= y[train_idx], y[test_idx]\n",
    "    vect= CountVectorizer(max_features=1000, binary=True)\n",
    "    X_train_vect= vect.fit_transform(X_train)\n",
    "    X_test_vect = vect.transform(X_test)\n",
    "    sm= SMOTE()\n",
    "    X_train_res, y_train_res= sm.fit_sample(X_train_vect, y_train)\n",
    "    predictions = train_model(naive_bayes.MultinomialNB(),X_train_res,y_train_res,X_test_vect)\n",
    "    alg_accurcy_NBM.append(accuracy_score(predictions, y_test))\n",
    "    score_array_NBM.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "    \n",
    "    predictions = train_model(svm.SVC(),X_train_res,y_train_res,X_test_vect)\n",
    "    alg_accurcy_SVM.append(accuracy_score(predictions, y_test))\n",
    "    score_array_SVM.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "    \n",
    "    predictions = train_model(linear_model.LogisticRegression(),X_train_res,y_train_res,X_test_vect)\n",
    "    alg_accurcy_LR.append(accuracy_score(predictions, y_test))\n",
    "    score_array_LR.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "    \n",
    "    predictions = train_model(ensemble.RandomForestClassifier(),X_train_res,y_train_res,X_test_vect)\n",
    "    alg_accurcy_RF.append(accuracy_score(predictions, y_test))\n",
    "    score_array_RF.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "\n",
    "average_accuracy_NBM= np.mean(alg_accurcy_NBM, axis=0)\n",
    "print(\"the average accuracy of NBM is\",average_accuracy_NBM)\n",
    "\n",
    "average_accuracy_SVM= np.mean(alg_accurcy_SVM, axis=0)\n",
    "print(\"the average accuracy of SVM is\",average_accuracy_SVM)\n",
    "\n",
    "average_accuracy_LR= np.mean(alg_accurcy_LR, axis=0)\n",
    "print(\"the average accuracy of LR is\",average_accuracy_LR)\n",
    "\n",
    "average_accuracy_RF= np.mean(alg_accurcy_RF, axis=0)\n",
    "print(\"the average accuracy of RF is\",average_accuracy_RF)\n",
    "    \n",
    "average_scire_NBM=np.mean(score_array_NBM, axis=0)\n",
    "print(average_scire_NBM)\n",
    "\n",
    "average_scire_SVM=np.mean(score_array_SVM, axis=0)\n",
    "print(average_scire_SVM)\n",
    "\n",
    "average_scire_LR=np.mean(score_array_LR, axis=0)\n",
    "print(average_scire_LR)\n",
    "\n",
    "average_scire_RF=np.mean(score_array_RF, axis=0)\n",
    "print(average_scire_RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average accuracy of NBM is 0.5440897889210329\n",
      "the average accuracy of SVM is 0.6928790313939784\n",
      "the average accuracy of LR is 0.6558630665380906\n",
      "the average accuracy of RF is 0.6519114968391728\n",
      "[[  0.8304317    0.3740099    0.23163931]\n",
      " [  0.51034187   0.6788862    0.41054305]\n",
      " [  0.62820908   0.47484691   0.29257829]\n",
      " [207.6         66.7         30.8       ]]\n",
      "[[7.24512215e-01 5.44302755e-01 3.68618904e-01]\n",
      " [9.27993522e-01 1.93698739e-01 1.32952386e-01]\n",
      " [8.10316196e-01 2.26043158e-01 1.83013566e-01]\n",
      " [2.07600000e+02 6.67000000e+01 3.08000000e+01]]\n",
      "[[  0.81758993   0.49433542   0.26672169]\n",
      " [  0.70838805   0.59021739   0.39099197]\n",
      " [  0.75778966   0.52964632   0.31357865]\n",
      " [207.6         66.7         30.8       ]]\n",
      "[[7.28029696e-01 4.24134645e-01 2.70648651e-01]\n",
      " [8.31382513e-01 3.24751927e-01 1.45068067e-01]\n",
      " [7.74132026e-01 3.60317711e-01 1.81017752e-01]\n",
      " [2.07600000e+02 6.67000000e+01 3.08000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "#Kfold classification for NBM, SVM, LR and RF using TFIDF\n",
    "\n",
    "kf= KFold(n_splits=10)\n",
    "#curr_fold= 0\n",
    "alg_accurcy_NBM_tfidf =[]\n",
    "alg_accurcy_SVM_tfidf =[]\n",
    "alg_accurcy_LR_tfidf =[]\n",
    "alg_accurcy_RF_tfidf =[]\n",
    "\n",
    "\n",
    "\n",
    "#x_train_tfidf\n",
    "\n",
    "score_array_NBM_tfidf= []\n",
    "score_array_SVM_tfidf= []\n",
    "score_array_LR_tfidf= []\n",
    "score_array_RF_tfidf= []\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test= X[train_idx], X[test_idx]\n",
    "    y_train, y_test= y[train_idx], y[test_idx]\n",
    "    tfidf_vect= TfidfVectorizer(analyzer='word', token_pattern= r'\\w{1,}', max_features=5000)\n",
    "    tfidf_vect.fit(X_train)\n",
    "    x_train_tfidf=tfidf_vect.transform(X_train)\n",
    "    x_test_tfidf=tfidf_vect.transform(X_test)\n",
    "    sm= SMOTE()\n",
    "    X_train_res_tfidf, y_train_res_tfidf= sm.fit_sample(x_train_tfidf, y_train)\n",
    "    predictions = train_model(naive_bayes.MultinomialNB(),X_train_res_tfidf,y_train_res_tfidf,x_test_tfidf)\n",
    "    alg_accurcy_NBM_tfidf.append(accuracy_score(predictions, y_test))\n",
    "    score_array_NBM_tfidf.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "    \n",
    "    predictions = train_model(svm.SVC(),X_train_res_tfidf,y_train_res_tfidf,x_test_tfidf)\n",
    "    alg_accurcy_SVM_tfidf.append(accuracy_score(predictions, y_test))\n",
    "    score_array_SVM_tfidf.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "    \n",
    "    predictions = train_model(linear_model.LogisticRegression(),X_train_res_tfidf,y_train_res_tfidf,x_test_tfidf)\n",
    "    alg_accurcy_LR_tfidf.append(accuracy_score(predictions, y_test))\n",
    "    score_array_LR_tfidf.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "    \n",
    "    predictions = train_model(ensemble.RandomForestClassifier(),X_train_res_tfidf,y_train_res_tfidf,x_test_tfidf)\n",
    "    alg_accurcy_RF_tfidf.append(accuracy_score(predictions, y_test))\n",
    "    score_array_RF_tfidf.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "\n",
    "average_accuracy_NBM_tfidf= np.mean(alg_accurcy_NBM_tfidf, axis=0)\n",
    "print(\"the average accuracy of NBM is\",average_accuracy_NBM_tfidf)\n",
    "\n",
    "average_accuracy_SVM_tfidf= np.mean(alg_accurcy_SVM_tfidf, axis=0)\n",
    "print(\"the average accuracy of SVM is\",average_accuracy_SVM_tfidf)\n",
    "\n",
    "average_accuracy_LR_tfidf= np.mean(alg_accurcy_LR_tfidf, axis=0)\n",
    "print(\"the average accuracy of LR is\",average_accuracy_LR_tfidf)\n",
    "\n",
    "average_accuracy_RF_tfidf= np.mean(alg_accurcy_RF_tfidf, axis=0)\n",
    "print(\"the average accuracy of RF is\",average_accuracy_RF_tfidf)\n",
    "    \n",
    "average_scire_NBM_tfidf=np.mean(score_array_NBM_tfidf, axis=0)\n",
    "print(average_scire_NBM_tfidf)\n",
    "\n",
    "average_scire_SVM_tfidf=np.mean(score_array_SVM_tfidf, axis=0)\n",
    "print(average_scire_SVM_tfidf)\n",
    "\n",
    "average_scire_LR_tfidf=np.mean(score_array_LR_tfidf, axis=0)\n",
    "print(average_scire_LR_tfidf)\n",
    "\n",
    "average_scire_RF_tfidf=np.mean(score_array_RF_tfidf, axis=0)\n",
    "print(average_scire_RF_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average accuracy of NBM is 0.6270213221900783\n",
      "the average accuracy of SVM is 0.7046758812814744\n",
      "the average accuracy of LR is 0.6738862102217936\n",
      "the average accuracy of RF is 0.6764963034394086\n",
      "[[  0.80474553   0.45945649   0.25700409]\n",
      " [  0.66569744   0.5706636    0.42532253]\n",
      " [  0.72736417   0.50188116   0.31788387]\n",
      " [207.6         66.7         30.8       ]]\n",
      "[[7.14715630e-01 7.29616013e-01 4.08582916e-01]\n",
      " [9.56558659e-01 1.35984919e-01 1.91756775e-01]\n",
      " [8.16621943e-01 2.11690059e-01 2.49375240e-01]\n",
      " [2.07600000e+02 6.67000000e+01 3.08000000e+01]]\n",
      "[[  0.80838834   0.4824616    0.34438654]\n",
      " [  0.74065483   0.56173773   0.41185349]\n",
      " [  0.77217195   0.51364985   0.36935123]\n",
      " [207.6         66.7         30.8       ]]\n",
      "[[7.31677333e-01 4.61607504e-01 2.53886166e-01]\n",
      " [8.73389310e-01 3.04440812e-01 1.28610818e-01]\n",
      " [7.95249014e-01 3.62079170e-01 1.65182496e-01]\n",
      " [2.07600000e+02 6.67000000e+01 3.08000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "#Kfold classification for NBM, SVM, LR and RF using TFIDF-ngram with analizer= 'word' and ngram=1-3\n",
    "\n",
    "kf= KFold(n_splits=10)\n",
    "#curr_fold= 0\n",
    "alg_accurcy_NBM_tfidf_W_ngram =[]\n",
    "alg_accurcy_SVM_tfidf_W_ngram =[]\n",
    "alg_accurcy_LR_tfidf_W_ngram =[]\n",
    "alg_accurcy_RF_tfidf_W_ngram =[]\n",
    "\n",
    "\n",
    "\n",
    "#x_train_tfidf\n",
    "\n",
    "score_array_NBM_tfidf_W_ngram= []\n",
    "score_array_SVM_tfidf_W_ngram= []\n",
    "score_array_LR_tfidf_W_ngram= []\n",
    "score_array_RF_tfidf_W_ngram= []\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test= X[train_idx], X[test_idx]\n",
    "    y_train, y_test= y[train_idx], y[test_idx]\n",
    "    \n",
    "    tfidf_vect_ngram= TfidfVectorizer(analyzer='word', token_pattern= r'\\w{1,}', ngram_range=(1,3), max_features=5000)\n",
    "    tfidf_vect_ngram.fit(X_train)\n",
    "    x_train_ngram=tfidf_vect_ngram.transform(X_train)\n",
    "    x_test_ngram=tfidf_vect_ngram.transform(X_test)\n",
    "    \n",
    "    sm= SMOTE()\n",
    "    X_train_res_tfidf_ngram, y_train_res_tfidf_ngram= sm.fit_sample(x_train_ngram, y_train)\n",
    "\n",
    "    \n",
    "    predictions = train_model(naive_bayes.MultinomialNB(),X_train_res_tfidf_ngram,y_train_res_tfidf_ngram,x_test_ngram)\n",
    "    alg_accurcy_NBM_tfidf_W_ngram.append(accuracy_score(predictions, y_test))\n",
    "    score_array_NBM_tfidf_W_ngram.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    \n",
    "    predictions = train_model(svm.SVC(),X_train_res_tfidf_ngram,y_train_res_tfidf_ngram,x_test_ngram)\n",
    "    alg_accurcy_SVM_tfidf_W_ngram.append(accuracy_score(predictions, y_test))\n",
    "    score_array_SVM_tfidf_W_ngram.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    \n",
    "    predictions = train_model(linear_model.LogisticRegression(),X_train_res_tfidf_ngram,y_train_res_tfidf_ngram,x_test_ngram)\n",
    "    alg_accurcy_LR_tfidf_W_ngram.append(accuracy_score(predictions, y_test))\n",
    "    score_array_LR_tfidf_W_ngram.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    \n",
    "    predictions = train_model(ensemble.RandomForestClassifier(),X_train_res_tfidf_ngram,y_train_res_tfidf_ngram,x_test_ngram)\n",
    "    alg_accurcy_RF_tfidf_W_ngram.append(accuracy_score(predictions, y_test))\n",
    "    score_array_RF_tfidf_W_ngram.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "\n",
    "average_accuracy_NBM_tfidf_W_ngram= np.mean(alg_accurcy_NBM_tfidf_W_ngram, axis=0)\n",
    "print(\"the average accuracy of NBM is\",average_accuracy_NBM_tfidf_W_ngram)\n",
    "\n",
    "average_accuracy_SVM_tfidf_W_ngram= np.mean(alg_accurcy_SVM_tfidf_W_ngram, axis=0)\n",
    "print(\"the average accuracy of SVM is\",average_accuracy_SVM_tfidf_W_ngram)\n",
    "\n",
    "average_accuracy_LR_tfidf_W_ngram= np.mean(alg_accurcy_LR_tfidf_W_ngram, axis=0)\n",
    "print(\"the average accuracy of LR is\",average_accuracy_LR_tfidf_W_ngram)\n",
    "\n",
    "average_accuracy_RF_tfidf_W_ngram= np.mean(alg_accurcy_RF_tfidf_W_ngram, axis=0)\n",
    "print(\"the average accuracy of RF is\",average_accuracy_RF_tfidf_W_ngram)\n",
    "    \n",
    "average_scire_NBM_tfidf_W_ngram=np.mean(score_array_NBM_tfidf_W_ngram, axis=0)\n",
    "print(average_scire_NBM_tfidf_W_ngram)\n",
    "\n",
    "average_scire_SVM_tfidf_W_ngram=np.mean(score_array_SVM_tfidf_W_ngram, axis=0)\n",
    "print(average_scire_SVM_tfidf_W_ngram)\n",
    "\n",
    "average_scire_LR_tfidf_W_ngram=np.mean(score_array_LR_tfidf_W_ngram, axis=0)\n",
    "print(average_scire_LR_tfidf_W_ngram)\n",
    "\n",
    "average_scire_RF_tfidf_W_ngram=np.mean(score_array_RF_tfidf_W_ngram, axis=0)\n",
    "print(average_scire_RF_tfidf_W_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the average accuracy of NBM is 0.5689842494374798\n",
      "the average accuracy of SVM is 0.5656991321118611\n",
      "the average accuracy of LR is 0.6640522875816993\n",
      "the average accuracy of RF is 0.6443790849673203\n",
      "[[  0.83562737   0.38362572   0.2915371 ]\n",
      " [  0.53632153   0.63864064   0.58033173]\n",
      " [  0.6501667    0.47303927   0.3855659 ]\n",
      " [207.6         66.7         30.8       ]]\n",
      "[[7.24512215e-01 5.44302755e-01 3.68618904e-01]\n",
      " [9.27993522e-01 1.93698739e-01 1.32952386e-01]\n",
      " [8.10316196e-01 2.26043158e-01 1.83013566e-01]\n",
      " [2.07600000e+02 6.67000000e+01 3.08000000e+01]]\n",
      "[[  0.81135119   0.46323728   0.36329722]\n",
      " [  0.72024925   0.55759654   0.489544  ]\n",
      " [  0.76155636   0.49915719   0.41318473]\n",
      " [207.6         66.7         30.8       ]]\n",
      "[[7.16004009e-01 3.73401758e-01 2.82033873e-01]\n",
      " [8.36635820e-01 2.71762760e-01 1.31284780e-01]\n",
      " [7.70001418e-01 3.09052437e-01 1.73564834e-01]\n",
      " [2.07600000e+02 6.67000000e+01 3.08000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "#Kfold classification for NBM, SVM, LR and RF using TFIDF-ngram with analizer= 'char' and ngram=1-3\n",
    "\n",
    "kf= KFold(n_splits=10)\n",
    "#curr_fold= 0\n",
    "alg_accurcy_NBM_C_tfidf =[]\n",
    "alg_accurcy_SVM_C_tfidf =[]\n",
    "alg_accurcy_LR_C_tfidf =[]\n",
    "alg_accurcy_RF_C_tfidf =[]\n",
    "\n",
    "\n",
    "\n",
    "#x_train_tfidf\n",
    "\n",
    "score_array_NBM_C_tfidf= []\n",
    "score_array_SVM_C_tfidf= []\n",
    "score_array_LR_C_tfidf= []\n",
    "score_array_RF_C_tfidf= []\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "    X_train, X_test= X[train_idx], X[test_idx]\n",
    "    y_train, y_test= y[train_idx], y[test_idx]\n",
    "    tfidf_vect_ngram_chars= TfidfVectorizer(analyzer='char', token_pattern= r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "    tfidf_vect_ngram_chars.fit(X_train)\n",
    "    x_train_ngram_char=tfidf_vect_ngram_chars.transform(X_train)\n",
    "    x_test_ngram_char=tfidf_vect_ngram_chars.transform(X_test)\n",
    "    sm= SMOTE()\n",
    "    X_train_res_tfidf_ngram_char, y_train_res_tfidf_ngram_char= sm.fit_sample(x_train_ngram_char, y_train)\n",
    "    \n",
    "    predictions = train_model(naive_bayes.MultinomialNB(),X_train_res_tfidf_ngram_char,y_train_res_tfidf_ngram_char,x_test_ngram_char)\n",
    "    alg_accurcy_NBM_C_tfidf.append(accuracy_score(predictions, y_test))\n",
    "    score_array_NBM_C_tfidf.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "    \n",
    "    predictions = train_model(svm.SVC(),X_train_res_tfidf_ngram_char,y_train_res_tfidf_ngram_char,x_test_ngram_char)\n",
    "    alg_accurcy_SVM_C_tfidf.append(accuracy_score(predictions, y_test))\n",
    "    score_array_SVM_C_tfidf.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "    \n",
    "    predictions = train_model(linear_model.LogisticRegression(),X_train_res_tfidf_ngram_char,y_train_res_tfidf_ngram_char,x_test_ngram_char)\n",
    "    alg_accurcy_LR_C_tfidf.append(accuracy_score(predictions, y_test))\n",
    "    score_array_LR_C_tfidf.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "    \n",
    "    predictions = train_model(ensemble.RandomForestClassifier(),X_train_res_tfidf_ngram_char,y_train_res_tfidf_ngram_char,x_test_ngram_char)\n",
    "    alg_accurcy_RF_C_tfidf.append(accuracy_score(predictions, y_test))\n",
    "    score_array_RF_C_tfidf.append(precision_recall_fscore_support(y_test,predictions, average=None))\n",
    "    #print(classification_report(y_test, predictions,target_names=my_tags))\n",
    "\n",
    "average_accuracy_NBM_C_tfidf= np.mean(alg_accurcy_NBM_C_tfidf, axis=0)\n",
    "print(\"the average accuracy of NBM is\",average_accuracy_NBM_C_tfidf)\n",
    "\n",
    "average_accuracy_SVM_C_tfidf= np.mean(alg_accurcy_SVM_C_tfidf, axis=0)\n",
    "print(\"the average accuracy of SVM is\",average_accuracy_SVM_C_tfidf)\n",
    "\n",
    "average_accuracy_LR_C_tfidf= np.mean(alg_accurcy_LR_C_tfidf, axis=0)\n",
    "print(\"the average accuracy of LR is\",average_accuracy_LR_C_tfidf)\n",
    "\n",
    "average_accuracy_RF_C_tfidf= np.mean(alg_accurcy_RF_C_tfidf, axis=0)\n",
    "print(\"the average accuracy of RF is\",average_accuracy_RF_C_tfidf)\n",
    "    \n",
    "average_scire_NBM_C_tfidf=np.mean(score_array_NBM_C_tfidf, axis=0)\n",
    "print(average_scire_NBM_C_tfidf)\n",
    "\n",
    "average_scire_SVM_C_tfidf=np.mean(score_array_SVM_C_tfidf, axis=0)\n",
    "print(average_scire_SVM_tfidf)\n",
    "\n",
    "average_scire_LR_C_tfidf=np.mean(score_array_LR_C_tfidf, axis=0)\n",
    "print(average_scire_LR_C_tfidf)\n",
    "\n",
    "average_scire_RF_C_tfidf=np.mean(score_array_RF_C_tfidf, axis=0)\n",
    "print(average_scire_RF_C_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Voting Mechanism\n",
    "\n",
    "predictions0 = train_model(naive_bayes.MultinomialNB(),X_train_res,y_train_res,X_test_vect)\n",
    "predictions1 = train_model(svm.SVC(),X_train_res_tfidf_ngram,y_train_res_tfidf_ngram,x_test_ngram)\n",
    "predictions2 = train_model(linear_model.LogisticRegression(),X_train_res_tfidf_ngram,y_train_res_tfidf_ngram,x_test_ngram)\n",
    "predictions3 = train_model(ensemble.RandomForestClassifier(),X_train_res_tfidf_ngram,y_train_res_tfidf_ngram,x_test_ngram)\n",
    "#predictions4 = train_model(xgboost.XGBClassifier(),X_train_res.tocsc(),y_train_res,X_test_vect.tocsc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7394366197183099\n",
      "f1 0.5186382245205775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " new feature       0.74      0.97      0.84        96\n",
      "       claim       1.00      0.17      0.29        18\n",
      "       issue       0.64      0.32      0.43        28\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       142\n",
      "   macro avg       0.80      0.49      0.52       142\n",
      "weighted avg       0.76      0.74      0.69       142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "multi_prediction = [];\n",
    "for i in range(len(predictions0)):\n",
    "    temp = []\n",
    "    temp.append(predictions0[i])\n",
    "    temp.append(predictions1[i])\n",
    "    temp.append(predictions2[i])\n",
    "    temp.append(predictions3[i])\n",
    "    #temp.append(predictions4[i])\n",
    "    multi_prediction.append(max(set(temp), key=temp.count))\n",
    "print('accuracy %s' % accuracy_score(multi_prediction, y_test))\n",
    "print('f1 %s' % f1_score(multi_prediction, y_test, average='macro'))\n",
    "print(classification_report(y_test, multi_prediction,target_names=my_tags))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
