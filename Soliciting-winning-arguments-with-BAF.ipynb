{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'9clgh7': ['e5bqkhk', 'e5bwn4g', 'e5btxu4', 'e5bmpya', 'e5bs4w3', 'e5c9mr9', 'e5bwzrb', 'e5d5dph', 'e5d3fyg', 'e5d237r', 'e5colkv', 'e5bumvv', 'e5bhqef', 'e5c1e4u', 'e5bs6c7', 'e5bhr9p', 'e5crv0y', 'e5bpnup', 'e5bi1ce', 'e5bh1by'], 'e5bqkhk': ['e5c4xqn'], 'e5bs6c7': ['e5c7vu0', 'e5d41nl', 'e5c08ws'], 'e5c7vu0': ['e5d85sh', 'e5cgv1o'], 'e5c08ws': ['e5c3xex'], 'e5bhr9p': ['e5choob', 'e5bixvt'], 'e5bixvt': ['e5bqzlk', 'e5bo31c', 'e5bqj1h'], 'e5bqzlk': ['e5ciyid'], 'e5bo31c': ['e5bv6i3', 'e5bwgvp'], 'e5crv0y': ['e5cv318'], 'e5bpnup': ['e5bu127'], 'e5bu127': ['e5d9oa2', 'e5c2txt'], 'e5c2txt': ['e5chm3o'], 'e5bi1ce': ['e5bs0cs', 'e5c03j5', 'e5bu0gl', 'e5bo4qs'], 'e5bs0cs': ['e5c0qe6'], 'e5c0qe6': ['e5c574t'], 'e5c574t': ['e5d7mqx'], 'e5d7mqx': ['e5d9jcp'], 'e5d9jcp': ['e5dizid'], 'e5bo4qs': ['e5bqf79'], 'e5bqf79': ['e5bv2j3'], 'e5bh1by': ['e5bhwu7', 'e5bk8f0', 'e5bhsdu'], 'e5bhwu7': ['e5c001z'], 'e5c001z': ['e5chi75', 'e5d0jfz'], 'e5d0jfz': ['e5daofw'], 'e5daofw': ['e5dbmuv'], 'e5bk8f0': ['e5bu4b5'], 'e5bu4b5': ['e5diuxz'], 'e5bhsdu': ['e5bzx5i', 'e5bo0t5'], 'e5bzx5i': ['e5ctlzb'], 'e5ctlzb': ['e5djgug', 'e5cyx3h', 'e5cwhu1'], 'e5cyx3h': ['e5czfpz'], 'e5czfpz': ['e5dbn4z', 'e5d6vd7'], 'e5bo0t5': ['e5c9tbc']}\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('Google Maps is testing a combined Commute tab to replace Driving and Transit.csv')\n",
    "#df.head(10)\n",
    "\n",
    "########function#####\n",
    "\n",
    "def create_dictionary(key,values):\n",
    "    node_edges_list= {}  \n",
    "    #print(values)\n",
    "    for x in key:\n",
    "        node_edges_list[x]=values     \n",
    "                      \n",
    "        #print(node_edges_list)\n",
    "    return(node_edges_list)\n",
    "\n",
    "######end-funtion####\n",
    "\n",
    "########## Bepth First search Algorithem########\n",
    "def dfs(graph, node, visited=[]):\n",
    "    print(\"graph is \", graph)\n",
    "    print(\"node is \",node)\n",
    "    print(\"the visited nodes are \",visited)\n",
    "    visited.append(node)\n",
    "    for n in graph[node]:\n",
    "        if n not in visited:\n",
    "              \n",
    "            print(\"value of n is \", n)\n",
    "            print(\"value of graph[node] is \", graph[node])\n",
    "            visited= dfs(graph,n, visited)\n",
    "    return visited\n",
    "\n",
    "################# End Algorithem##############\n",
    "\n",
    "\n",
    "nodes= df['comment_Text']\n",
    "lista= [] #create empty list\n",
    "node_edges= {} # empty dictionary for making nodes-edges pairs\n",
    "final_node_edges_dic={}\n",
    "#edges1= ['0','9clgh7', 'e5bqkhk']\n",
    "edges1= df['parent_id'].unique() # get unique colums values\n",
    "remove_top_element=list(edges1)  # convert array into list\n",
    "remove_top_element.pop(0) # remove top element from list which is root node\n",
    "#print(remove_top_element)\n",
    "#print(edges1)\n",
    "for edge in range(len(remove_top_element)): # code for making pairs of edges and nodes from the dataset\n",
    "    #print(edges1[edge])\n",
    "    lista.append(remove_top_element[edge])\n",
    "    #print(\"parent_id\",lista)\n",
    "    edge_single=df.loc[df['parent_id'].isin(lista)] #get comments based on primary key and forign key\n",
    "    edges_vertices=edge_single['comment_id'].values.tolist() # get correspoding comment_id for each vertices, which will shows possible reation between 2 vertices\n",
    "    #edges_vertices_list.append(edges_vertices) #getting values from dataform and convert that into list.\n",
    "    #print(\"comments_id\",edges_vertices)\n",
    "    node_edges= create_dictionary(lista,edges_vertices)\n",
    "    final_node_edges_dic.update(node_edges) \n",
    "    \n",
    "    lista =[]\n",
    "#graph= {1:[2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20], 2:[21], 21: [], 3:[]}\n",
    "print(final_node_edges_dic) #final list of pairs\n",
    "#visited = dfs(final_node_edges_dic,'9clgh7')\n",
    "#print(visited)\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['e5dbn4z'], ['e5dizid'], ['e5d9jcp'], ['e5chm3o'], ['e5ciyid'], ['e5c9tbc', 'e5bo0t5'], ['e5diuxz'], ['e5c2txt'], ['e5d9oa2'], ['e5bqzlk'], ['e5bk8f0'], ['e5bqj1h', 'e5bixvt'], ['e5choob'], ['e5d41nl'], ['e5bv2j3', 'e5c0qe6', 'e5bs0cs', 'e5c03j5', 'e5bo4qs', 'e5c574t', 'e5bqf79', 'e5d7mqx'], ['e5cv318', 'e5crv0y'], ['e5bhr9p'], ['e5c3xex', 'e5c08ws', 'e5d85sh', 'e5cgv1o', 'e5bs6c7'], ['e5c1e4u'], ['e5bumvv'], ['e5d237r'], ['e5d3fyg'], ['e5c9mr9'], ['e5bmpya'], ['e5btxu4'], ['e5bwn4g'], ['e5bqkhk'], ['e5cyx3h', 'e5d0jfz', 'e5bzx5i', 'e5djgug', 'e5d6vd7', 'e5dbmuv', 'e5bu127', 'e5bhwu7', 'e5bh1by', 'e5cwhu1', 'e5bs4w3', 'e5bpnup']]\n"
     ]
    }
   ],
   "source": [
    "father_children = final_node_edges_dic\n",
    "node_height = {}\n",
    "for father in father_children:\n",
    "    cur_height = 0\n",
    "    if father in node_height:\n",
    "        cur_height = node_height[father]\n",
    "    else:\n",
    "        node_height[father] = 0\n",
    "    children = father_children[father]\n",
    "    for child in children:\n",
    "        if child not in node_height:\n",
    "            node_height[child] = cur_height + 1\n",
    "node_height = sorted(node_height.items(), key=lambda d:d[1], reverse=False)\n",
    "O = [x[0] for x in node_height]\n",
    "\n",
    "children_father = {}\n",
    "for father in father_children:\n",
    "    children = father_children[father]\n",
    "    for child in children:\n",
    "        children_father[child] = father\n",
    "\n",
    "comment_ids = df[\"comment_id\"]\n",
    "tags = df[\"Rationale_Type\"]\n",
    "tags = tags.fillna(0)\n",
    "id_tag = {}\n",
    "for index, comment_id in comment_ids.items():\n",
    "    id_tag[comment_id] = tags[index]\n",
    "    \n",
    "D_S_Set = {}\n",
    "T_S_Set = {}\n",
    "N_Set = {}\n",
    "\n",
    "O.reverse()\n",
    "\n",
    "for node in O:\n",
    "    D_S_Set[node] = []\n",
    "    T_S_Set[node] = []\n",
    "    N_Set[node] = []\n",
    "    if node in father_children:\n",
    "        for child in father_children[node]:\n",
    "            if id_tag[child] == \"claim-support\":\n",
    "                D_S_Set[node].append(child)\n",
    "            elif id_tag[child] == \"claim-attack\":\n",
    "                N_Set[node].append(child)\n",
    "\n",
    "\n",
    "\n",
    "ResSet = []\n",
    "ignore_list = []\n",
    "for N in O:\n",
    "    if id_tag[N] == \"issue\" or id_tag[N] == \"feature\" or id_tag[N] == 0:\n",
    "        result_Set = N_Set[N]  \n",
    "        for node in ignore_list:\n",
    "            if node in result_Set:\n",
    "                result_Set.remove(node)\n",
    "        if len(result_Set) != 0:\n",
    "            ignore_list.append(N) \n",
    "            for node in D_S_Set[N]:\n",
    "                ignore_list.append(node)\n",
    "        result_Set = D_S_Set[N] + T_S_Set[N] + N_Set[N] + [N]\n",
    "        for node in ignore_list:\n",
    "            if node in result_Set:\n",
    "                result_Set.remove(node)\n",
    "        ResSet.append(result_Set)\n",
    "    else:\n",
    "        if id_tag[N][:5] == \"claim\":\n",
    "            f = children_father[N]\n",
    "            if len(N_Set[N]) != 0:\n",
    "                for node in ignore_list:\n",
    "                    if node in N_Set[N]:\n",
    "                        N_Set[N].remove(node)\n",
    "                if len(N_Set[N]) != 0:\n",
    "                    ignore_list.append(N)\n",
    "                    for node in D_S_Set[N]:\n",
    "                        ignore_list.append(node)\n",
    "            if id_tag[N][-7:] == \"support\":\n",
    "                D_S_Set[f] = list(set(D_S_Set[f] + D_S_Set[N]))\n",
    "                T_S_Set[f] = list(set(T_S_Set[f] + T_S_Set[N]))\n",
    "                N_Set[f] = list(set(N_Set[f] + N_Set[N]))\n",
    "            elif id_tag[N][-6:] == \"attack\":\n",
    "                N_Set[f] = list(set(N_Set[f] + D_S_Set[N]))\n",
    "                N_Set[f] = list(set(N_Set[f] + T_S_Set[N]))\n",
    "                T_S_Set[f] = list(set(T_S_Set[f] + N_Set[N]))\n",
    "print(ResSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
